# Developer Quick-Start Guide

**Version**: 1.0  
**Date**: February 1, 2026  
**Status**: MVP Onboarding  
**Audience**: New developers implementing COE features

---

## Overview

This guide helps new developers quickly orient to the COE codebase and understand the **PRD update workflow** across development stages.

**Time to productive**: 30 minutes reading + 1 hour setup

---

## Step 1: Initial Setup (5 minutes)

### Prerequisites
- VS Code installed
- Node.js 18+ installed
- Git configured
- GitHub account with personal access token (PAT)

### Clone & Install
```bash
git clone https://github.com/your-org/coe-extension.git
cd coe-extension
npm install
```

### Workspace Structure
```
${workspaceRoot}/
‚îú‚îÄ‚îÄ plan.md                   ‚Üê User-created feature plan
‚îú‚îÄ‚îÄ .coe/
‚îÇ   ‚îú‚îÄ‚îÄ PRD.md                ‚Üê Auto-generated by Planning Team
‚îÇ   ‚îú‚îÄ‚îÄ PRD.json              ‚Üê Machine-readable version
‚îÇ   ‚îú‚îÄ‚îÄ tickets.db            ‚Üê SQLite tickets
‚îÇ   ‚îú‚îÄ‚îÄ state.json            ‚Üê Agent state
‚îÇ   ‚îî‚îÄ‚îÄ agents/
‚îÇ       ‚îú‚îÄ‚îÄ clarity-agent/config.yaml
‚îÇ       ‚îú‚îÄ‚îÄ planning-team/config.yaml
‚îÇ       ‚îî‚îÄ‚îÄ orchestrator/config.yaml
‚îî‚îÄ‚îÄ src/                       ‚Üê Extension source code
```

### Create Your First Plan
```bash
# Option 1: From template
cp templates/plan-template.md plan.md
# Edit plan.md with your feature requirements

# Option 2: Use Planning Wizard (UI)
code .
# Open Command Palette (Ctrl+Shift+P)
# Run: "COE: Create New Plan"
```

---

## Step 2: PRD Generation & Structure (10 minutes)

### Auto-Generate PRD from Plan

**When**: After `plan.md` is created or updated

**How**:
```bash
# Run PRD generation script
npm run generate-prd

# Or via VS Code command
# Command Palette ‚Üí "COE: Generate PRD"
```

**Output**: 
- `.coe/PRD.md` (human-readable)
- `.coe/PRD.json` (machine-readable for agents)

### PRD.md Structure (MVP)

```markdown
# Project Requirements Document

## Project Info
- **Plan ID**: my-app
- **Version**: 1.0.0
- **Generated**: 2026-02-01T12:00:00Z

## Features by Priority

### P1 (Critical)
- User Authentication (login/register)
- Task CRUD operations
- Dashboard view

### P2 (High)
- Search & filter
- Notifications

### P3 (Nice-to-Have)
- Dark mode
- Export to CSV

## Acceptance Criteria

### User Authentication
- ‚úÖ Login form validates email format
- ‚úÖ Password field masked during input
- ‚úÖ JWT token returned on successful auth
- ‚è≥ Password reset flow (Stage 2)

## Agent Progress (Auto-Updated)

| Agent | Status | Tasks Generated | Tasks Complete | Last Update |
|-------|--------|-----------------|----------------|-------------|
| Planning Team | ‚úÖ Complete | 12 | 12 | 2026-02-01 10:00 |
| Orchestrator | ‚è≥ In Progress | - | 8 / 12 | 2026-02-01 12:30 |
| Verification Team | ‚è≥ Pending | - | 6 / 8 | 2026-02-01 12:25 |

## Verification Status

### Completed Features
- ‚úÖ User login (all tests pass)
- ‚úÖ Task creation (verified)

### In Progress
- ‚è≥ Task editing (Copilot coding)

### Blocked
- üö® Dashboard view (waiting for design clarification - Ticket TK-0445)
```

---

## Step 3: PRD Update Policy Across Development Stages

### When to Update PRD

| Trigger | Action | Who Updates | How |
|---------|--------|-------------|-----|
| **Plan.md modified** | Regenerate PRD | Auto (file watcher) | `npm run generate-prd` |
| **Task completed** | Update "Agent Progress" section | Planning Team agent | Auto via MCP `reportTaskStatus` |
| **Feature verified** | Mark feature ‚úÖ in "Verification Status" | Verification Team | Auto after tests pass |
| **Ticket created** | Add to "Blocked" section | Clarity Agent | Auto on ticket creation |
| **Stage transition** (MVP ‚Üí Stage 2) | Add "Stage 2 Features" section | Developer | Manual: `npm run update-prd --stage=2` |

### Stage Transition Workflow

**Scenario**: Moving from MVP (Stage 1) to Stage 2 (add Researcher agent, advanced features)

**Steps**:
1. **Review current PRD**: Check all MVP features completed
   ```bash
   cat .coe/PRD.md | grep "Verification Status"
   # Ensure all MVP features marked ‚úÖ
   ```

2. **Update plan.md**: Add Stage 2 features
   ```markdown
   <!-- plan.md -->
   ## Stage 2 Features (Post-MVP)
   - Advanced search with filters
   - Researcher agent for documentation scraping
   - Critic agent for error pattern analysis
   ```

3. **Run stage update script**:
   ```bash
   npm run update-prd --stage=2
   # This appends Stage 2 section to PRD.md
   ```

4. **Review diff**:
   ```bash
   git diff .coe/PRD.md
   # Check new sections added correctly
   ```

5. **Commit PRD changes**:
   ```bash
   git add .coe/PRD.md plan.md
   git commit -m "Add Stage 2 features to PRD"
   ```

### PRD Update Examples by Stage

**Stage 1 ‚Üí Stage 2** (Researcher + Critic agents):
```markdown
## Stage 2 Features (Added 2026-02-15)

### New Agents
- **Researcher Agent**: Documentation scraping, API reference lookup
- **Critic Agent**: Error pattern analysis, UV task proposals

### New Acceptance Criteria
- Researcher can scrape MDN docs (< 5s response)
- Critic detects repeated errors (‚â•3 occurrences in 24h)
```

**Stage 2 ‚Üí Stage 3** (Boss AI + complex workflows):
```markdown
## Stage 3 Features (Added 2026-03-01)

### New Capabilities
- **Boss AI**: High-level coordination, conflict resolution
- **Multi-agent workflows**: Planning + Researcher collaboration
- **Advanced error recovery**: Pattern-based auto-fixes
```

---

## Step 4: File Organization (5 minutes)

### Key Documentation Files (Reading Order)

**Core Architecture** (30 min total):
1. [CONSOLIDATED-MASTER-PLAN.md](CONSOLIDATED-MASTER-PLAN.md) (5 min) ‚Äî High-level system overview
2. [02-Agent-Role-Definitions.md](02-Agent-Role-Definitions.md) (10 min) ‚Äî Agent responsibilities
3. [AGENT-RESPONSIBILITIES-MATRIX.md](AGENT-RESPONSIBILITIES-MATRIX.md) (5 min) ‚Äî Handoff decision trees
4. [MODULAR-EXECUTION-PHILOSOPHY.md](MODULAR-EXECUTION-PHILOSOPHY.md) (5 min) ‚Äî Task size standards
5. [TICKET-SYSTEM-SPECIFICATION.md](TICKET-SYSTEM-SPECIFICATION.md) (5 min) ‚Äî Ticket schema + flows

**Integration Details** (20 min total):
6. [04-Data-Flow-State-Management.md](04-Data-Flow-State-Management.md) (7 min) ‚Äî Ticket‚ÜíTask pipeline
7. [05-MCP-API-Reference.md](05-MCP-API-Reference.md) (8 min) ‚Äî Tool specs + error cases
8. [08-Context-Management-System.md](08-Context-Management-System.md) (5 min) ‚Äî UI events + refresh

**Testing & Security** (15 min total):
9. [E2E-AGENT-COORDINATION-TEST.md](E2E-AGENT-COORDINATION-TEST.md) (5 min) ‚Äî E2E test scenario
10. [SECURITY-AUTHENTICATION-SPEC.md](SECURITY-AUTHENTICATION-SPEC.md) (5 min) ‚Äî Auth + data protection
11. [10-MCP-Error-Codes-Registry.md](10-MCP-Error-Codes-Registry.md) (5 min) ‚Äî Error handling

---

## Step 5: First Implementation Task (10 minutes)

### Recommended Starting Point: Ticket CRUD + SQLite Schema

**Why**: Foundational component, clear acceptance criteria, well-documented

**References**:
- Spec: [TICKET-SYSTEM-SPECIFICATION.md](TICKET-SYSTEM-SPECIFICATION.md)
- Tests: [ticketdb-test-fixes-breakdown.md](ticketdb-test-fixes-breakdown.md)
- Error handling: [10-MCP-Error-Codes-Registry.md](10-MCP-Error-Codes-Registry.md)

**Acceptance Criteria**:
- [ ] SQLite database initialized at `.coe/tickets.db`
- [ ] Schema includes `version` column (optimistic concurrency)
- [ ] CRUD methods: `createTicket`, `getTicket`, `updateTicket`, `deleteTicket`
- [ ] All methods use parameterized queries (SQL injection prevention)
- [ ] Update conflict detection triggers `TICKET_UPDATE_CONFLICT` error
- [ ] File permissions set to 600 (user-only read/write)
- [ ] Unit tests pass (from ticketdb-test-fixes-breakdown.md)

**Estimated Time**: 90 minutes for experienced dev, 120 minutes for beginner

---

## Key Concepts (Beginner-Friendly)

### 1. Atomic Task = 15‚Äì45 Minutes

**Definition**: A task that can be completed, tested, and verified independently in 15-45 minutes.

**Why**: Keeps context tight, prevents mid-task overflow, enables atomic verification.

**Enforcement**: Orchestrator rejects tasks > 45 min (must be decomposed first).

**See**: [MODULAR-EXECUTION-PHILOSOPHY.md ‚Ä∫ 3. Time Box](MODULAR-EXECUTION-PHILOSOPHY.md)

---

### 2. PRD.md = Source of Truth

**Definition**: PRD.md (and PRD.json) are the canonical reference for all features, acceptance criteria, and progress.

**Why**: Prevents plan drift, ensures agents consult same source, enables traceability.

**Rule**: All agents MUST consult PRD before acting (Planning, Orchestrator, Answer Team, Verification).

**See**: [CONSOLIDATED-MASTER-PLAN.md ‚Ä∫ PRD & Plan File Generation](CONSOLIDATED-MASTER-PLAN.md)

---

### 3. Ticket System = All AI-Human Coordination

**Definition**: All coordinated AI-human interactions route through tickets (not ad-hoc chat).

**Why**: Traceability, clarity enforcement (Clarity Agent scores replies), async communication.

**Rule**: Copilot questions ‚Üí tickets, Verification issues ‚Üí tickets, User clarifications ‚Üí tickets.

**See**: [TICKET-SYSTEM-SPECIFICATION.md ‚Ä∫ "No Chat Fallback" Clarification](TICKET-SYSTEM-SPECIFICATION.md)

---

### 4. MCP = Transport Layer

**Definition**: Model Context Protocol (MCP) is JSON-RPC over stdio for Copilot ‚Üî COE communication.

**Tools**: `getNextTask`, `reportTaskStatus`, `askQuestion`, `createTicket`, etc.

**See**: [05-MCP-API-Reference.md](05-MCP-API-Reference.md)

---

### 5. Event-Driven UI (Not Polling)

**Definition**: Sidebar tabs refresh via events (MCP server emits changes), not periodic polling.

**Why**: Real-time updates, reduced CPU usage, better UX.

**Events**: `onTasksChanged`, `onTicketsChanged`, `onAgentStateChanged`

**See**: [08-Context-Management-System.md ‚Ä∫ UI State Events](08-Context-Management-System.md)

---

## Common Beginner Pitfalls (And How to Avoid Them)

### Pitfall 1: Creating Tasks > 45 Minutes

**Problem**: "I created a task 'Build entire auth system' (120 min est.). Is this valid?"

**Solution**: NO. Planning Team will reject it. Use Task Decomposition Agent to break into 3-4 sub-tasks (each ‚â§ 45 min).

**See**: [AGENT-RESPONSIBILITIES-MATRIX.md ‚Ä∫ Decision 1: Planning ‚Üí Decomposition](AGENT-RESPONSIBILITIES-MATRIX.md)

---

### Pitfall 2: Updating PRD Manually Without Script

**Problem**: "I edited PRD.md directly. Now agents see stale data."

**Solution**: ALWAYS use `npm run generate-prd` or file watcher. Manual edits risk PRD.json mismatch.

**Rule**: PRD.md is generated, not hand-written (except for Stage transition notes).

---

### Pitfall 3: Storing Secrets in Ticket Content

**Problem**: "I put my API key in a ticket for reference. Is this secure?"

**Solution**: NO. Tickets stored in plaintext SQLite (MVP). Use `context.secrets` for credentials.

**See**: [SECURITY-AUTHENTICATION-SPEC.md ‚Ä∫ Sensitive Data Detection](SECURITY-AUTHENTICATION-SPEC.md)

---

### Pitfall 4: Assuming Sidebar Auto-Refreshes Without Events

**Problem**: "I updated ticket in DB, but sidebar still shows old data. Bug?"

**Solution**: Ensure MCP server emits `onTicketsChanged` event. Sidebar listens for events, not polling.

**See**: [08-Context-Management-System.md ‚Ä∫ Refresh Trigger Matrix](08-Context-Management-System.md)

---

## ENV Variable Setup (First-Time Developer)

### Required Environment Variables

Create `.env` file in workspace root (NOT committed to git):

```bash
# GitHub Personal Access Token
GITHUB_TOKEN=ghp_...

# LLM Configuration (if using local model)
LLM_MODEL=qwen2-14b
LLM_API_ENDPOINT=http://localhost:11434  # Ollama endpoint

# Optional: Copilot API (handled by Copilot extension, usually)
COPILOT_TOKEN=...
```

**Security Note**: Add `.env` to `.gitignore` BEFORE committing!

---

## Troubleshooting (Quick Fixes)

| Problem | Likely Cause | Fix |
|---------|--------------|-----|
| "PRD.md not found" | Never generated | Run `npm run generate-prd` |
| "Ticket DB locked" | Concurrent writes | Retry; check `TICKET_UPDATE_CONFLICT` error handling |
| "Sidebar not refreshing" | Event emitter not wired | Check `onDidChangeTreeData.fire()` calls |
| "Task > 45 min rejected" | Needs decomposition | Send to Task Decomposition Agent |
| "GitHub sync paused" | Rate limit hit | Wait for reset (check notification banner) |
| "Copilot timeout" | LLM too slow or unreachable | Check LLM endpoint, increase timeout config |

---

## Next Steps After Setup

1. **Read E2E test scenario**: [E2E-AGENT-COORDINATION-TEST.md](E2E-AGENT-COORDINATION-TEST.md) to see full workflow
2. **Implement Ticket CRUD**: Start with `src/services/ticketDb.ts`
3. **Run tests**: `npm test` ‚Äî ensure all unit tests pass
4. **Start extension**: `F5` in VS Code (launches Extension Development Host)
5. **Test in action**: Create a plan, generate PRD, create ticket, see sidebar update

---

## Step 6: LM Studio / Local LLM Setup (10 minutes)

**Purpose**: COE agents (Planning, Answer, Clarity) require a local LLM for autonomous decision-making. LM Studio provides an easy-to-use interface for running models locally.

### Option 1: LM Studio (Recommended for Beginners)

**Download & Install**:
1. Go to https://lmstudio.ai
2. Download for your OS (Windows/Mac/Linux)
3. Install and launch

**Load a Model**:
1. Open LM Studio
2. Click "Discover" tab
3. Search for compatible model: `qwen2-7b-instruct` (fast, 7GB) or `qwen2-14b-instruct` (better quality, 14GB)
4. Download model (may take 10-30 min depending on network)
5. Once downloaded, click "Load Model"

**Start Local Server**:
1. Click "Local Server" tab in LM Studio
2. Click "Start Server"
3. Default endpoint: `http://localhost:1234`
4. Verify server running: Open browser ‚Üí `http://localhost:1234/v1/models` ‚Üí Should show loaded model

**Configure COE to Use LM Studio**:
Edit `.coe/agents/*/config.yaml` files:
```yaml
llm:
  endpoint: "http://localhost:1234/v1"  # LM Studio endpoint
  model: "qwen2-7b-instruct"            # Target model name
  timeout_seconds: 30                   # Request timeout
  model_load_timeout_minutes: 30        # Max time to wait for model loading
  check_loaded_model_first: true        # Skip reload if already loaded
```

**‚ö†Ô∏è CRITICAL: LLM Loading Behavior**

LM Studio has important loading constraints you MUST account for:

1. **Loading Time**: Switching models can take **up to 30 minutes** (especially for 14B+ models)
2. **Single Model Limit**: Only **ONE model can be loaded at a time** (no concurrent models)
3. **Hot Load Feature**: You can make API calls even if model isn't loaded ‚Äî LM Studio will auto-start loading
4. **Model Check API**: Use `/v1/models` endpoint to check which model (if any) is currently loaded

**Recommended Process** (avoid unnecessary 30-min waits):

```typescript
// 1. Check what's currently loaded
const loadedModels = await fetch('http://localhost:1234/v1/models').then(r => r.json());
const currentModel = loadedModels.data[0]?.id;  // e.g., "qwen2-7b-instruct"

// 2. If it's already the model we need, skip loading
if (currentModel === targetModel) {
  console.log(`Model ${targetModel} already loaded ‚Äî proceeding immediately`);
  return callLlm(prompt);  // No wait needed
}

// 3. If different model is loaded or none loaded, trigger load + wait
if (currentModel && currentModel !== targetModel) {
  console.warn(`Model switch required: ${currentModel} ‚Üí ${targetModel}`);
  console.warn(`This may take up to 30 minutes. Starting hot load...`);
}

// 4. Make the call (hot load: LM Studio starts loading if needed)
const response = await callLlmWithLoadTimeout(prompt, {
  model: targetModel,
  loadTimeoutMinutes: 30  // Wait up to 30 min for model to load
});
```

**Why This Matters**:
- ‚ùå **Bad**: Blindly calling LLM without checking ‚Üí 30-min wait every time model switches
- ‚úÖ **Good**: Check first ‚Üí instant response if model already loaded
- ‚úÖ **Best**: Cache current model state, only switch when absolutely necessary

**Test Connection**:
```bash
# Run health check
npm run test:llm-health

# Or manual curl test
curl http://localhost:1234/v1/models
# Should return: {"data": [{"id": "qwen2-7b-instruct", ...}]}
```

### Option 2: Ollama (Advanced, CLI-based)

**Install Ollama**:
```bash
# macOS / Linux
curl -fsSL https://ollama.com/install.sh | sh

# Windows (PowerShell admin)
winget install Ollama.Ollama
```

**Pull & Run Model**:
```bash
ollama pull qwen2:7b
ollama serve  # Starts server on localhost:11434
```

**Configure COE**:
```yaml
llm:
  endpoint: "http://localhost:11434"  # Ollama endpoint
  model: "qwen2:7b"
```

### Option 3: Network LLM (Multi-Machine Setup)

**Use Case**: Run LLM on a powerful desktop, access from development laptop.

**Setup**:
1. On powerful machine: Start LM Studio ‚Üí Enable "Network Mode" (bind to `0.0.0.0`)
2. Note IP address (e.g., `192.168.1.205`)
3. On dev machine: Configure agents:
```yaml
llm:
  endpoint: "http://192.168.1.205:1234/v1"  # Network IP
```

**Security Note**: Only use on trusted local network (no authentication in LM Studio server).

### Troubleshooting Common LLM Issues

| Issue | Symptom | Fix |
|---|---|---|
| **Port conflict** | "Address already in use" | Change LM Studio port (Settings ‚Üí Server ‚Üí Port 1235) |
| **Model not loaded** | API returns 404 | Load model in LM Studio UI first |
| **Timeout errors** | Requests take >30s | Reduce context size or use faster model (7B vs 14B) |
| **GPU OOM** | Model crashes mid-inference | Reduce batch size in LM Studio settings or use CPU mode |
| **Connection refused** | Can't reach endpoint | Check firewall, verify server running (`netstat -an | grep 1234`) |

### Verify LLM Integration

**Run E2E Test**:
```bash
# Test full workflow: Planning ‚Üí LLM call ‚Üí Answer ‚Üí Verify
npm run test:e2e:llm

# Expected output:
# ‚úÖ Planning Team: Generated task breakdown
# ‚úÖ Answer Team: Responded to question (confidence: 92%)
# ‚úÖ Clarity Agent: Scored ticket reply (score: 88/100)
```

**Manual Test in Extension**:
1. Press `F5` to launch Extension Development Host
2. Open Command Palette ‚Üí "COE: Ask Answer Team"
3. Enter question: "What is the purpose of Clarity Agent?"
4. Should receive LLM-generated answer with sources (if integrated correctly)

### Performance Expectations

| Model | RAM Required | Inference Speed | Use Case |
|---|---|---|---|
| qwen2-7b | 8 GB | ~15 tokens/sec (CPU) | Fast responses, good for Clarity scoring |
| qwen2-14b | 16 GB | ~8 tokens/sec (CPU) | Better quality for Planning/Answer |
| llama3-70b | 48 GB+ | ~2 tokens/sec (GPU) | Production-quality (not recommended for dev) |

**Recommendation for MVP**: Start with `qwen2-7b-instruct` on LM Studio ‚Äî easiest setup + fast enough for development.

**Reference**: See `LLM info` folder for additional configuration examples and model comparisons.

---

## Links to Templates & Examples

- **Plan Template**: `templates/plan-template.md`
- **Agent Config Templates**: [AGENT-CONFIG-TEMPLATES.md](AGENT-CONFIG-TEMPLATES.md)
- **Test Examples**: `tests/fixtures/` (sample tickets, tasks, agents)
- **Mermaid Diagram Patterns**: [AI-USE-SYSTEM-DIAGRAMS.md](AI-USE-SYSTEM-DIAGRAMS.md)

---

## Getting Help

- **Documentation Index**: [AI-TEAMS-DOCUMENTATION-INDEX.md](AI-TEAMS-DOCUMENTATION-INDEX.md)
- **Quick Reference**: [QUICK-REFERENCE-CARD.md](QUICK-REFERENCE-CARD.md)
- **Agent Matrix**: [AGENT-RESPONSIBILITIES-MATRIX.md](AGENT-RESPONSIBILITIES-MATRIX.md) (decision trees)
- **Error Codes**: [10-MCP-Error-Codes-Registry.md](10-MCP-Error-Codes-Registry.md)

**Questions?** Check existing ticket system examples in `TICKET-SYSTEM-SPECIFICATION.md` or create a GitHub issue.

---

**Welcome to COE development! üöÄ**
