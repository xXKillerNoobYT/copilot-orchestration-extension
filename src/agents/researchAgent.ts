import { logInfo, logError } from '../logger';
import { completeLLM } from '../services/llmService';

/**
 * Research Agent: Performs detailed research queries and generates MD reports
 * Simulates time-intensive research with configurable delay
 */
export class ResearchAgent {
    private readonly RESEARCH_DELAY_MS = 600000; // 10 minutes
    private readonly SYSTEM_PROMPT = 
        'You are a research assistant. Generate a detailed markdown research report ' +
        'on the following topic. Structure your response with:\n' +
        '1. A brief summary (2-3 sentences)\n' +
        '2. Key findings (4-6 bullet points)\n' +
        '3. Detailed analysis (2-3 paragraphs)\n' +
        '4. Relevant considerations or implications\n\n' +
        'Be comprehensive, factual, and well-organized. Use markdown formatting.';

    /**
     * Run research on the given query and generate a markdown report
     * @param query - The research topic or question
     * @returns Formatted markdown research report
     */
    async runResearch(query: string): Promise<string> {
        logInfo(`[ResearchAgent] Starting research for query: "${query.substring(0, 100)}${query.length > 100 ? '...' : ''}"`);

        try {
            // Simulate time-intensive research process
            logInfo(`[ResearchAgent] Simulating research delay (${this.RESEARCH_DELAY_MS / 1000}s)...`);
            await new Promise(resolve => setTimeout(resolve, this.RESEARCH_DELAY_MS));

            logInfo('[ResearchAgent] Delay complete, generating research report...');

            // Generate research using LLM
            const response = await completeLLM(query, {
                systemPrompt: this.SYSTEM_PROMPT,
                temperature: 0.7
            });

            logInfo(`[ResearchAgent] Research complete. Generated ${response.content.length} characters.`);

            // Format into structured markdown report
            const report = this.formatReport(query, response.content);
            return report;

        } catch (error: unknown) {
            const errorMessage = error instanceof Error ? error.message : String(error);
            logError(`[ResearchAgent] Research failed: ${errorMessage}`);
            
            // Return error report instead of throwing
            return this.formatErrorReport(query, errorMessage);
        }
    }

    /**
     * Format the LLM response into a structured markdown report
     * @param query - Original research query
     * @param content - LLM-generated content
     * @returns Formatted markdown report
     */
    private formatReport(query: string, content: string): string {
        const timestamp = new Date().toLocaleString('en-US', {
            dateStyle: 'full',
            timeStyle: 'short'
        });

        return `# Research Report: ${query}

**Generated:** ${timestamp}

---

${content}

---

*Generated by COE Research Agent*
`;
    }

    /**
     * Format an error message into a markdown report
     * @param query - Original research query
     * @param errorMessage - Error details
     * @returns Formatted error markdown
     */
    private formatErrorReport(query: string, errorMessage: string): string {
        const timestamp = new Date().toLocaleString('en-US', {
            dateStyle: 'full',
            timeStyle: 'short'
        });

        return `# Research Error

**Query:** ${query}  
**Generated:** ${timestamp}

---

## Error Details

Failed to generate research report: ${errorMessage}

The Research Agent encountered an issue while processing your query. This may be due to:
- LLM service unavailability
- Network connectivity issues
- Query processing errors

Please try again later or check the COE logs for more details.

---

*COE Research Agent*
`;
    }
}
